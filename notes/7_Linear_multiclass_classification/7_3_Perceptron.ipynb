{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7: Linear multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  7.3  Multi-Class Classification and the Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Section we discuss a natural alternative to OvA multi-class classification detailed in the previous Section.   Instead of training $C$ two class classifiers *first* and *then* fusing them into a single decision boundary (via the *fusion rule*), we can train all $C$ classifiers *simultaneously* to explicitly satisfy the fusion rule directly.  In particular here we derive the *Multi-class Perceptron* cost for achieving this feat, which can be thought of as a direct generalization of the two class perceptron described in [Section 6.4](https://jermwatt.github.io/machine_learning_refined/notes/6_Linear_twoclass_classification/6_4_Perceptron.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libs\n",
    "import os\n",
    "\n",
    "# if on collab pull required subdirectories\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"): \n",
    "    # install github clone - allows for easy cloning of subdirectories\n",
    "    !pip install github-clone\n",
    "    from pathlib import Path \n",
    "\n",
    "    # clone datasets\n",
    "    if not Path('chapter_7_library').is_dir():\n",
    "        !ghclone https://github.com/mlr2dev/machine_learning_refined_q1_2023_dev/tree/j_branch/notes/7_Linear_multiclass_classification/chapter_7_library\n",
    "    else:\n",
    "        print('chapter_7_library already cloned!')\n",
    "\n",
    "    # clone library subdirectory\n",
    "    if not Path('chapter_7_datasets').is_dir():\n",
    "        !ghclone https://github.com/mlr2dev/machine_learning_refined_q1_2023_dev/tree/j_branch/notes/7_Linear_multiclass_classification/chapter_7_datasets\n",
    "    else:\n",
    "        print('chapter_7_datasets already cloned!')\n",
    "\n",
    "    # clone datasets\n",
    "    if not Path('chapter_7_images').is_dir():\n",
    "        !ghclone https://github.com/mlr2dev/machine_learning_refined_q1_2023_dev/tree/j_branch/notes/7_Linear_multiclass_classification/chapter_7_images\n",
    "    else:\n",
    "        print('chapter_7_images already cloned!')\n",
    "        \n",
    "\n",
    "# append path for local library, data, and image import\n",
    "import sys\n",
    "sys.path.append('./chapter_7_library') \n",
    "sys.path.append('./chapter_7_images') \n",
    "sys.path.append('./chapter_7_datasets') \n",
    "\n",
    "# import section helper\n",
    "import section_7_3_helpers\n",
    "\n",
    "# dataset paths\n",
    "dataset_path_1 = 'chapter_7_datasets/3class_data.csv'\n",
    "dataset_path_2 = 'chapter_7_datasets/4class_data.csv'\n",
    "\n",
    "# standard imports\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "# this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Multi-class Perceptron cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we deal with an arbitrary multi-class dataset $\\left\\{ \\left(\\mathbf{x}_{p,}\\,y_{p}\\right)\\right\\} _{p=1}^{P}$\n",
    "consisting of $C$ distinct classes of data.  The labels for these classes can be made arbitrarily, but here we will once again employ label values $y_{p}\\in\\left\\{ 0,1,...,C-1\\right\\} $.  \n",
    "\n",
    "In the previous Section on OvA multi-class classification we saw how the fusion rule rightfully defined class ownership, partitioning the input space of a dataset given its classes in a fair way.  In particular the fusion rule should *ideally when all weights are properly tuned* predict precisely the labels of our dataset as often as possible as\n",
    "\n",
    "\\begin{equation}\n",
    "y_p =   \\underset{c \\,=\\, 0,...,C-1}{\\text{argmax}} \\,\\,\\,\\mathring{\\mathbf{x}}_{p}^T \\mathbf{w}_c^{\\,}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim in this Section is - instead of tuning our each classifier's weights one-by-one and then combining them in this way - to *learn all sets of weights simultaneously so as to satisfy this ideal condition as often as possible*.  Note that for now we will ignore the the beneift of *normalizing* each set of weights $\\mathbf{w}_j$, since as discussed in the prior Section this is often ignored in practice.  We will however re-introduce the concept in Section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started in constructing a proper cost function by which our ideal weights can be determined upon proper minimization, first note that for the *if* the above is to hold for our $p^{th}$ point then we can likewise say that the following is true as well\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,} = \\underset{c \\,=\\, 0,...,C-1}{\\text{max}} \\,\\,\\,\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}.\n",
    "\\end{equation}\n",
    "\n",
    "Remember geometrically this simply says that the (signed) distance from the point $\\mathbf{x}_p$ to its class decision boundary is greater than its distance from every other class's. This is what we want for all of our training datapoints - to have the prediction provided by the fusion rule match our given labels, and hence the above to be true for every point $\\mathbf{x}_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition - when these weights are are tuned optimally - the right hand side of equation (2) must always be greater than or equal to the left, since the $y_p^{th}$ classifier is considered in the maximum on the right hand side.  This means that their difference - subtracting $\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}$ from both sides - gives a pointwise cost that is *always nonnegative* and minimal at zero\n",
    "\n",
    "\\begin{equation}\n",
    "g_p\\left(\\mathbf{w}_0,...,\\mathbf{w}_{C-1}\\right) = \\left(\\underset{c \\,=\\, 0,...,C-1}{\\text{max}} \\,\\,\\,\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}\\right) - \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our weights are set ideally this value should be zero for as many points as possible - i.e., so that the weights $\\mathbf{w}_{y_p}^{\\,}$ have been tuned correctly so that indeed the $y_p^{th}$ classifier provides the largest evaluation of $\\mathbf{x}_p$. With this in mind, we can then easily form a cost function by taking the *average* of the pointwise cost above as $\\frac{1}{P}\\sum_{p = 1}^P g_p$ or equivalently \n",
    "\n",
    "\\begin{equation}\n",
    "g\\left(\\mathbf{w}_{0}^{\\,},\\,...,\\mathbf{w}_{C-1}^{\\,}\\right) = \\frac{1}{P}\\sum_{p = 1}^P \\left[ \\left(\\underset{c \\,=\\, 0,...,C-1}{\\text{max}} \\,\\,\\,\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}\\right) - \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "This *multi-class Perceptron* cost function is nonnegative and - when weights are tuned correctly - is as small as possible.  Thus we can stop *assuming* that we have ideal weights, and minimize this cost in order to find them.  Note here that unlike the OvA - detailed in the previous Section - here we tune all weights *simultaneously* in order to recover weights that satisfy the fusion rule in equation (1) as well as possible.  Like its two class analog (see [Section 6.4](https://jermwatt.github.io/machine_learning_refined/notes/6_Linear_twoclass_classification/6_4_Perceptron.html)) - the multi-class Perceptron is also *convex* regardless of the dataset employed (also see this Chapter's exercises for further details).  It also has a *trivial solution at zero*, that is when $\\mathbf{w}_c = \\mathbf{0}$ for all $c$ the cost is minimal which is to be avoided (which is often achievable by initializing any local optimization scheme used to minimize it away from the origin). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Nomenclature and alternative formulations of the multi-class Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call this the *multi-class Perceptron cost* not only because we have derived it by studying the problem of multi-class classification 'from above' as we did in [Section 6.4](https://jermwatt.github.io/machine_learning_refined/notes/6_Linear_twoclass_classification/6_4_Perceptron.html), but also due to the fact that it can be easily shown to be a direct generalization of the two class version introduced in Section 6.4.1.  One easy way to see this is rewrite it - in order to make its appearence more akin to its two class analog - by combining the two terms in each summand using the following simple property of the $\\text{max}$ function\n",
    "\n",
    "\\begin{equation}\n",
    "{\\text{max}} \\left(s_0,\\,s_1,...,s_{C-1}\\right) - z = {\\text{max}} \\left(s_0 - z,\\,s_1 - z,...,s_{C-1} - z\\right)\n",
    "\\end{equation}\n",
    "\n",
    "where $s_0,\\,s_1,...,s_{C-1}$ and $z$ are scalar values.  Using this we can combine both terms in the $p^{th}$ summand andre-write the multi-class Perceptron in equation (4) cost function as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "g\\left(\\mathbf{w}_{0}^{\\,},\\,...,\\mathbf{w}_{C-1}^{\\,}\\right) = \\frac{1}{P}\\sum_{p = 1}^P \\underset{ \\underset{c \\neq y_p }{ c \\,=\\, 0,...,C-1}  }{\\text{max}} \\left(0,\\mathring{\\mathbf{x}}_{p}^T\\left( \\overset{\\,}{\\mathbf{w}}_c^{\\,} - \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}\\right)\\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the corresponding pointwise cost $g_p\\left(\\mathbf{w}_0,...,\\mathbf{w}_{C-1}\\right) = \\underset{ \\underset{c \\neq y_p }{ c \\,=\\, 0,...,C-1}  }{\\text{max}} \\left(0,\\mathring{\\mathbf{x}}_{p}^T\\left( \\overset{\\,}{\\mathbf{w}}_c^{\\,} - \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}\\right)\\right)$ now mirrors its the two class analog detailed in 6.4.1 more closely.  In this form it is straightforward to then show that when $C = 2$ the multi-class Perceptron reduces to the two class version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Regularization and the multi-class Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how in minimizing this cost we should - at least formally - subject it to the constraints that all feature-touching portions / normal vectors have unit length.  To express this we will employ our bias / feature-touching weight notation allowing us to decompose each weight vector $\\mathbf{w}_c$ into two components\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{(bias):}\\,\\, b_c = w_{0,c} \\,\\,\\,\\,\\,\\,\\,\\, \\text{(feature-touching weights):} \\,\\,\\,\\,\\,\\, \\boldsymbol{\\omega}_j = \n",
    "\\begin{bmatrix}\n",
    "w_{1,c} \\\\\n",
    "w_{2,c} \\\\ \n",
    "\\vdots \\\\\n",
    "w_{N,c}\n",
    "\\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "In this notation each linear combination can be written as $\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,} =  b_{c}^{\\,} + \\mathbf{x}_{p}^T\\boldsymbol{\\omega}_{c}^{\\,}$.\n",
    "\n",
    "\n",
    "The formal desire for the feature-touching weights from all $C$ classifiers to have unit length translates to $\\left \\Vert \\boldsymbol{\\omega}_{c}^{\\,} \\right \\Vert_2^2 = 1$ for all $c$. As detailed in the previous Section, formally speaking we need these normal vectors to be unit length if we are to fairly compare the distance of each input $\\mathbf{x}_p$ to our two-class decision boundaries.    Doing this, a proper *constrained optimization* problem involving our multi-class Perceptron takes the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\underset{b_{0}^{\\,},\\,\\boldsymbol{\\omega}_{0}^{\\,},\\,...,\\,b_{C-1}^{\\,},\\,\\boldsymbol{\\omega}_{C-1}^{\\,}}{\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\mbox{minimize}\\,\\,\\,} & \\,\\,\\,\\,  \\frac{1}{P}\\sum_{p = 1}^P \\left[\\left(\\underset{c \\,=\\, 0,...,C-1}{\\text{max}} \\,\\,\\,b_{c}^{\\,} + \\mathbf{x}_{p}^T\\boldsymbol{\\omega}_{c}^{\\,}\\right) - \\left(b_{y_p}^{\\,} + \\mathbf{x}_{p}^T\\boldsymbol{\\omega}_{y_p}^{\\,}\\right)\\right]\\\\\n",
    "\\mbox{subject to}\\,\\,\\, & \\,\\,\\,\\,\\, \\left \\Vert \\boldsymbol{\\omega}_{c}^{\\,} \\right \\Vert_2^2  = 1, \\,\\,\\,\\,\\,\\, c \\,=\\, 0,...,C-1\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "This is a proper cost function for *determining* proper weights for our $C$ classifiers: it is always nonnegative, we want to find weights so that its value is small, and it is precisely zero when all training points are classified correctly.  We can solve such problems directly in a variety of ways - e.g., by using projected gradient descent - but it is more commonplace to see this problem approximately solved by *relaxing the constraints* (as we have seen done many times before, e.g., in Sections [6.4.3](https://jermwatt.github.io/machine_learning_refined/notes/6_Linear_twoclass_classification/6_4_Perceptron.html) and [6.5.3](https://jermwatt.github.io/machine_learning_refined/notes/6_Linear_twoclass_classification/6_5_SVMs.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we can phrase this constrained problem in an unconstrained *regularized* form by relaxing the constraints but penalizing their magnitude. Because we have $C$ constraints we could in theory provide a distinct penalty (or regularization parameter) $\\lambda_j$ for each constraint. However for simplicity one can choose a single regularization parameter $\\lambda \\geq 0$ that is used to penalize the magnitude of all normal vectors simultaneously. This way we need only provide one regularization value instead of $C$ distinct regularization parameters, giving the regularized form of the above problem giving a regularized multi-class Perceptron cost function\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{P}\\sum_{p = 1}^P \\left[\\left(\\underset{c \\,=\\, 0,...,C-1}{\\text{max}} \\,\\,\\,b_{c}^{\\,} + \\mathbf{x}_{p}^T\\boldsymbol{\\omega}_{c}^{\\,}\\right) - \\left(b_{y_p}^{\\,} + \\mathbf{x}_{p}^T\\boldsymbol{\\omega}_{y_p}^{\\,}\\right)\\right]+ \\lambda \\sum_{c = 0}^{C-1} \\left \\Vert \\boldsymbol{\\omega}_{c}^{\\,} \\right \\Vert_2^2 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that must be minimized properly. This regularized form does not quite match the original constrained formulation as regularizing all normal vectors together will not necessarily guarantee that $\\left \\Vert \\boldsymbol{\\omega}_{c}^{\\,} \\right \\Vert_2^2 = 1$ for all $c$.  However it will generally force the length of all normal vectors to behave well, e.g., disallowing one normal vector to grow arbitrarily large while one shrinks to almost nothing. As we see many times in machine learning, it is commonplace to make such compromises to get something that is 'close enough' to the original as long as it does work well in practice. This is indeed the case here with $\\lambda$ typically set to a small value (e.g., $10^{-3}$ and smaller)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Implementing and minimizing a modular multi-class Perceptron in `Python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take advantage of the `numpy` libraries fast array operations we use the notation first initroduced in [Section 5.6.3](https://jermwatt.github.io/machine_learning_refined/notes/5_Linear_regression/5_6_Multi.html), and repeated in the previous Section, we stack the trained weights from our $C$ classifiers together into a single $\\left(N + 1\\right) \\times C$ array of the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{W}=\\begin{bmatrix} \n",
    "w_{0,0}  &  w_{0,1}  &  w_{0,2}  & \\cdots   &  w_{0,C-1}  \\\\\n",
    "w_{1,0}  &  w_{1,1}  &  w_{1,2}  & \\cdots  &   w_{1,C-1}  \\\\\n",
    "w_{2,0}  &  w_{2,1}  &  w_{2,2}  & \\cdots  &  w_{2,C-1}  \\\\\n",
    "\\,\\,\\, {\\vdots}_{\\,\\,\\,}  & {\\vdots}_{\\,\\,\\,}  &  {\\vdots}_{\\,\\,\\,}  &  \\cdots   &    {\\vdots}_{\\,\\,\\,}    \\\\\n",
    "w_{N,0}  &  w_{N,1} & w_{N,2}  &  \\cdots  &  w_{N,C-1}  \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the bias and normal vector of the $c^{th}$ classifier have been stacked on top of one another and make up the $c^{th}$ column of the array.  Now lets extend our `model` notation to also denote the evaluation of our $C$ individual linear models as\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{matrix} \n",
    "\\text{model}\\left(\\mathbf{x},\\mathbf{W}\\right) = \\mathring{\\mathbf{x}}_{\\,}^T\\mathbf{W} \\end{matrix}  = \\begin{bmatrix}\n",
    "\\mathring{\\mathbf{x}}_{\\,}^T  \\overset{\\,}{\\mathbf{w}}_{0}^{\\,}   &\n",
    "\\mathring{\\mathbf{x}}_{\\,}^T  \\overset{\\,}{\\mathbf{w}}_{1}^{\\,}   &\n",
    "\\cdots \\, &\n",
    "\\mathring{\\mathbf{x}}_{\\,}^T  \\overset{\\,}{\\mathbf{w}}_{C-1}^{\\,}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: not only is this the *same* linear model used in multi-output regression (as detailed in [Section 5.6](https://jermwatt.github.io/machine_learning_refined/notes/5_Linear_regression/5_6_Multi.html)), but the above is a $1\\times C$ array of our linear models that can be evaluated at any $\\mathbf{W}$.  We can now use precisely the same `model` implementation we have seen in Section 5.6.3, which we repeat below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute C linear combinations of input point, one per classifier\n",
    "def model(x,w):\n",
    "    a = w[0] + np.dot(x.T,w[1:])\n",
    "    return a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this `model` notation we can more conveniently implement essentially any formula derived from the fusion rule like e.g., the multi-class Perceptron.  For example, we can write the fusion rule itself equivalently as \n",
    "\n",
    "\\begin{equation}\n",
    "y = \\underset{c \\,=\\, 0,...,C-1} {\\text{max}}\\,\\text{model}\\left(\\mathbf{x},\\mathbf{W}\\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we can write the $p^{th}$ summand of the multi-class Perceptron compactly as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "\\left(\\underset{c \\,=\\, 0,...,C-1}{\\text{max}} \\,\\,\\,\\mathring{\\mathbf{x}}_{p}^T \\mathbf{w}_c^{\\,}\\right) - \\mathring{\\mathbf{x}}_{p}^T \\mathbf{w}_{y_p}^{\\,}. = \\left(\\underset{c \\,=\\, 0,...,C-1} {\\text{max}}\\,\\text{model}\\left(\\mathbf{x}_p,\\mathbf{W}\\right)\\right) - \\text{model}\\left(\\mathbf{x}_p,\\mathbf{W}\\right)_{y_p}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in mind we can then easily implement a multi-class Perceptron in `Python` looping over each point explicitly, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class perceptron regularized by the summed length of all normal vectors\n",
    "lam = 10**-5  # our regularization paramter \n",
    "def multiclass_perceptron(w):        \n",
    "    # pre-compute predictions on all points\n",
    "    all_evals = model(x,w)\n",
    "\n",
    "    # compute counting cost\n",
    "    cost = 0\n",
    "    for p in range(len(y)):\n",
    "        # pluck out current true label\n",
    "        y_p = y[p] \n",
    "\n",
    "        # update cost summand\n",
    "        cost +=  np.max(all_evals[p,:]) - all_evals[p,int(y_p)]\n",
    "        \n",
    "    # return cost with regularizer added\n",
    "    cost += lam*np.linalg.norm(w[1:,:],'fro')**2\n",
    "    return cost/float(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Python`` code often runs much faster when ``for`` loops - or equivalently ``list comprehensions`` - are written equivalently using matrix-vector ``numpy`` operations (this has been a constant theme in our implementations since linear regression in [Section 5.2](https://jermwatt.github.io/machine_learning_refined/notes/5_Linear_regression/5_2_Least.html)).  This often leads to more compact ``Python`` code as well, since ``for`` loop operations are often more compactly written (even mathematically) as a matrix-vector operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show an example of writing the ``multiclass_perceptron`` cost function more compactly than shown previously using ``numpy`` operations instead of the explicit ``for`` loop over the data points.  Both this and the previous implementation compute the same final result for a given set of input weights, but here the computation will be considerably (orders of magnitude) faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 10**-5  # our regularization paramter \n",
    "def multiclass_perceptron(w):        \n",
    "    # pre-compute predictions on all points\n",
    "    all_evals = model(x,w)\n",
    "    \n",
    "    # compute maximum across data points\n",
    "    a = np.max(all_evals,axis = 0)    \n",
    "\n",
    "    # compute cost in compact form using numpy broadcasting\n",
    "    b = all_evals[y.astype(int).flatten(),np.arange(np.size(y))]\n",
    "    cost = np.sum(a - b)\n",
    "    \n",
    "    # add regularizer\n",
    "    cost = cost + lam*np.linalg.norm(w[1:,:],'fro')**2\n",
    "    \n",
    "    # return average\n",
    "    return cost/float(np.size(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 1: </span> multi-class perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we minimize the regularized multi-class classifier defined above over a toy dataset with $C=3$ classes used in deriving OvA in the previous Section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "data = np.loadtxt(dataset_path_1,delimiter = ',')\n",
    "\n",
    "# get input/output pairs\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:] \n",
    "\n",
    "# create an instance of the ova demo\n",
    "demo = section_7_3_helpers.MulticlassVisualizer(data)\n",
    "\n",
    "# visualize dataset\n",
    "demo.show_dataset()\n",
    "\n",
    "# run gradient descent to minimize cost\n",
    "g = multiclass_perceptron; w = 0.1*np.random.randn(3,3); max_its = 2000; alpha_choice = 10**(-1);\n",
    "weight_history = demo.gradient_descent(g,w,alpha=alpha_choice,max_its=max_its)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our multi-class classifier trained by gradient descent we now show how it classifies the entire input space. In the left panel we plot each individual two-class classifier. In the middle panel we show the fused multi-class decision boundary formed by combining these individual classifiers via the fusion rule. In the right panel we plot the cost function value over $200$ iterations of gradient descent.\n",
    "\n",
    "Note in the left panel that because we did not train each individual classifier in an OvA sense - but trained them together all at once - each individual learned two-class classifier performs quite poorly.  This is fine as our cost function aimed at minimizing all errors of every class simultaneously and not two at a time as with OvA - so we need not expect each individual classifier to cut the space well. However since they were learned together their combination - using the fusion rule - provides a multi-class decision boundary with zero errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot classification of space, individual learned classifiers (left panel) and joint boundary (middle panel), and cost-function panel in the right panel\n",
    "demo.show_complete_coloring(weight_history, cost = multiclass_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The Multi-class Softmax / Cross Entropy cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw previously with the case of the two class perceptron in [Section 6.4](https://jermwatt.github.io/machine_learning_refined/notes/6_Linear_twoclass_classification/6_4_Perceptron.html), we are often willing to sacrifice a small amount of modeling precision - forming a closely matching smoother cost function to the one we already have - in order to make optimization easier or expand the optimization tools we can bring to bear.  As was the case with the two class perceptron, here too we can *smooth* the multi-class Perceptron cost employing the *softmax* function.  Recall from our discussion of the two class perceptron in Section 6.4.2 that the *softmax function*\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{soft}\\left(s_0,s_1,...,s_{C-1}\\right) = \\text{log}\\left(e^{s_0} + e^{s_1} + \\cdots + e^{s_{C-1}} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "is a close and smooth approximation to the maximum of $C$ scalar numbers $s_{0},...,s_{C-1}$, i.e.,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{soft}\\left(s_0,s_1,...,s_{C-1}\\right) \\approx \\text{max}\\left(s_0,s_1,...,s_{C-1}\\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the $\\text{max}$ function in each summand of the multi-class Perceptron *as written in equation (4)* above with its $\\text{softmax}$ approximation gives have the following cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "g\\left(\\mathbf{w}_{0}^{\\,},\\,...,\\mathbf{w}_{C-1}^{\\,}\\right) = \\frac{1}{P}\\sum_{p = 1}^P \\left[\\text{log}\\left( \\sum_{c = 0}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}}  \\right) - \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}\\right].\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is referred to as the *multi-class Softmax* cost function is convex but - unlike the Multiclass Perceptron - it has infinitely many smooth derivatives, hence we can use second order methods (in addition to gradient descent) in order to properly minimize it.  Notice that it also no longer has a trivial solution at zero, i.e., when $\\mathbf{w}_j = \\mathbf{0}$ for all $j$ (just as its two class analog removed this deficiency - see Section 6.4.3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomenclature and alternative formulations of the multi-class Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cost function goes by *many* names in practice including: the *multi-class Softmax*, *Multiclass Cross Entropy*, *Softplus*, and *Multiclass Logistic* cost to name a few.  We however will use two fundamental names to refer to it in general.  The first is *Multiclass Softmax*, which we use both because it is a softmax-smoothed version of the Multiclass Perceptron and because it is the natural generalization of the two class version seen in e.g., [Section 6.4.3](https://jermwatt.github.io/machine_learning_refined/notes/6_Linear_twoclass_classification/6_4_Perceptron.html).  To see this more easily let us smooth the formulation of the Multiclass Perceptron given in equation (6), replacing the $\\text{max}$ with the $\\text{softmax}$ approximation, giving an equivalent but different formulation than the one above\n",
    "\n",
    "\\begin{equation}\n",
    "g\\left(\\mathbf{w}_{0}^{\\,},\\,...,\\mathbf{w}_{C-1}^{\\,}\\right) = \\frac{1}{P}\\sum_{p = 1}^P  \\text{log}\\left(1 + \\sum_{\\underset{j \\neq y_p}{c = 0}}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\left(\\overset{\\,}{\\mathbf{w}}_c^{\\,} - \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}\\right)}  \\right).\n",
    "\\end{equation}\n",
    "\n",
    "Visually this appears more similar to the two class Softmax cost, and indeed does reduce to it when $C = 2$ (and $y_p \\in \\left\\{-1,+1\\right\\}$ are chosen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also refer to this function as the *multi-class Cross Entropy* cost because it is - likewise - a natrual generalization of the two class version seen in [Section 6.2](https://jermwatt.github.io/machine_learning_refined/notes/6_Linear_twoclass_classification/6_2_Cross_entropy.html).  To see that this indeed the case we can again re-express the Softmax cost in equation (16) in an equivalent but different way.  To do this note that we take its $p^{th}$ summand and rewrite it using the fact that $\\text{log}\\left(e^{s}\\right) = s$ as\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{log}\\left( \\sum_{c = 0}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}}  \\right) - \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,} = \\text{log}\\left( \\sum_{c = 0}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}}  \\right) - \\text{log}\\,e^{\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the $\\text{log}$ property that \n",
    "\n",
    "\\begin{equation}\n",
    " \\text{log}\\left(s\\right) - \\text{log}\\left(t\\right) = \\text{log}\\left(\\frac{s}{t}\\right) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to rewrite the above as \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{log}\\left( \\sum_{c = 0}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}}  \\right) - \\text{log}\\,e^{\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}} = \\text{log}\\left( \\frac{\\sum_{c = 0}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}}}  {e^{\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}}}    \\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally because by the $\\text{log}$ property that\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{log}\\left(s\\right) = -\\text{log}\\left(\\frac{1}{s}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "this can be rewritten equivalently as \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{log}\\left( \\frac{ \\sum_{c = 0}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}}}  {e^{\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}}}    \\right) = -\\text{log}\\left( \\frac{e^{\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}}}  {\\sum_{c = 0}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}} }    \\right) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in sum, we can rewrite \n",
    "\n",
    "\\begin{equation}\n",
    "g\\left(\\mathbf{w}_{0}^{\\,},\\,...,\\mathbf{w}_{C-1}^{\\,}\\right) = -\\frac{1}{P}\\sum_{p = 1}^P  \\text{log}\\left( \\frac{e^{\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}}}  {\\sum_{c = 0}^{C-1}  e^{ \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}} }    \\right) .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually this appears more similar to the two class Cross Entropy cost [1], and indeed does reduce to it in quite a straightforward manner when $C = 2$ (and $y_p \\in \\left\\{0,1\\right\\}$ are chosen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Regularization and the multi-class Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the multi-class Percpetron, it is common to *regularize* the Multiclass Softmax via its feature touching weights as \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{P}\\sum_{p = 1}^P \\left[\\text{log}\\left( \\sum_{c = 0}^{C-1}  e^{ b_{c}^{\\,} + \\mathbf{x}_{p}^T\\boldsymbol{\\omega}_{c}^{\\,} }  \\right) - \\left(b_{y_p}^{\\,} + \\mathbf{x}_{p}^T\\boldsymbol{\\omega}_{y_p}^{\\,}\\right)\\right] + \\lambda \\sum_{c = 0}^{C-1} \\left \\Vert \\boldsymbol{\\omega}_{c}^{\\,} \\right \\Vert_2^2 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\lambda \\geq 0$ is typically set to a small value like e.g., $10^{-3}$.  In addition to this being more formally appropriate - given that our cost funtions originate with the fusion rule established in the previous Section - this can also be interpreted as a way of preventing local optimization methods like Newton's method (which take large steps) from diverging when dealing with perfectly seperable data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Implementing and minimizing a modular multi-class softmax in `Python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement the multi-class Softmax cost very similar to how the Multiclass Perceptron was implemented above.  That is, using the compact model notation introduced there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{matrix} \n",
    "\\text{model}\\left(\\mathbf{x},\\mathbf{W}\\right) = \\mathring{\\mathbf{x}}_{\\,}^T\\mathbf{W} \\end{matrix}  = \\begin{bmatrix}\n",
    "\\mathring{\\mathbf{x}}_{\\,}^T  \\overset{\\,}{\\mathbf{w}}_{0}^{\\,}   &\n",
    "\\mathring{\\mathbf{x}}_{\\,}^T  \\overset{\\,}{\\mathbf{w}}_{1}^{\\,}   &\n",
    "\\cdots \\, &\n",
    "\\mathring{\\mathbf{x}}_{\\,}^T  \\overset{\\,}{\\mathbf{w}}_{C-1}^{\\,}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can likewise implement the evaluation of all $C$ classifiers simply as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute C linear combinations of input point, one per classifier\n",
    "def model(x,w):\n",
    "    a = w[0] + np.dot(x.T,w[1:])\n",
    "    return a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we can write the $p^{th}$ summand of the multi-class Softmax (as written in equation (16)) compactly as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "\\left(\\underset{c \\,=\\, 0,...,C-1}{\\text{softmax}} \\,\\,\\,\\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_c^{\\,}\\right) - \\mathring{\\mathbf{x}}_{p}^T \\overset{\\,}{\\mathbf{w}}_{y_p}^{\\,}. = \\left(\\underset{c \\,=\\, 0,...,C-1} {\\text{softmax}}\\,\\text{model}\\left(\\mathbf{x}_p,\\mathbf{W}\\right)\\right) - \\text{model}\\left(\\mathbf{x}_p,\\mathbf{W}\\right)_{y_p}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this more compact way of expressing the multi-class softmax - and with the module `model` having already been written above - we can quickly implement a `Python` efficient implementation of the Multi-class Softmax cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass softmaax regularized by the summed length of all normal vectors\n",
    "lam = 10**(-5)  # our regularization paramter \n",
    "def multiclass_softmax(w):        \n",
    "    # pre-compute predictions on all points\n",
    "    all_evals = model(x,w)\n",
    "    \n",
    "    # compute softmax across data points\n",
    "    a = np.log(np.sum(np.exp(all_evals),axis = 0)) \n",
    "    \n",
    "    # compute cost in compact form using numpy broadcasting\n",
    "    b = all_evals[y.astype(int).flatten(),np.arange(np.size(y))]\n",
    "    cost = np.sum(a - b)\n",
    "    \n",
    "    # add regularizer\n",
    "    cost = cost + lam*np.linalg.norm(w[1:,:],'fro')**2\n",
    "    \n",
    "    # return average\n",
    "    return cost/float(np.size(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 2: </span> Multi-class Softmax on a toy dataset with $C=3$ classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we run the multi-class softmax classifier on the same dataset used in the previous example, first using unnormalized gradient descent and then Newton's method.  In the next Python cell we implement a version of the multi-class softmax cost function complete with regularizer. The weights are formatted precisely as in our implementation of the multi-class perceptron, discussed in Example 1.  We then minimize the softmax cost function using gradient descent - for $200$ iterations using a fixed steplength value $\\alpha = 10^{-2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the final classification over the entire space in the left and middle panels while the cost function plot from our run of gradient descent is plotted in the right panel. In the left panel are shown the final learned two-class classifiers individually, in the middle the multi-class boundary created using these two-class boundaries and the fusion rule. As with the multi-class perceptron, since the multi-class softmax cost focuses on optimizing the parameters of all $C$ two-class classifiers simultaneously to get the best multi-class fit, each one of the two-class decision boundaries need not perfectly distinguish its class from the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "data = np.loadtxt(dataset_path_1,delimiter = ',')\n",
    "\n",
    "# create instance of multiclass visualizer\n",
    "demo = section_7_3_helpers.MulticlassVisualizer(data)\n",
    "\n",
    "# run gradient descent to minimize cost\n",
    "g = multiclass_softmax; w = 0.1*np.random.randn(3,3); max_its = 200; alpha_choice = 1;\n",
    "weight_history = demo.gradient_descent(g,w,alpha=alpha_choice,max_its=max_its)\n",
    "\n",
    "# plot classification of space, individual learned classifiers (left panel) and joint boundary (middle panel), and cost-function panel in the right panel\n",
    "demo.show_complete_coloring(weight_history, cost = multiclass_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing using Newton's method takes just a few steps: in the next cell we re-run the above experiment only using 5 Newton steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we then print out the same panels as previously, only displaying the results of Newton's method.  Using just a few steps we reach a far lower point on the Multi-class Softmax function - as can be seen by comparing the right panel below with the one shown previously with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run newtons method to minimize cost\n",
    "g = multiclass_softmax; w = 0.1*np.random.randn(3,3); max_its = 5; \n",
    "weight_history = demo.newtons_method(g,w,max_its=max_its)\n",
    "\n",
    "# plot classification of space, individual learned classifiers (left panel) and joint boundary (middle panel), and cost-function panel in the right panel\n",
    "demo.show_complete_coloring(weight_history, cost = multiclass_softmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 3: </span> Multi-class Softmax on a toy dataset with $C = 4$ classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we quickly apply Newton's method to fit the Multi-sclass Softmax cost to our toy dataset with $C=4$ classes.  Here points colred red, blue, green, and kahki have label values $y_p = 0$, $1$, $2$, and $3$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "data = np.loadtxt(dataset_path_2,delimiter = ',')\n",
    "\n",
    "# get input/output pairs\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:] \n",
    "\n",
    "# create instance of multiclass visualizer\n",
    "demo = section_7_3_helpers.MulticlassVisualizer(data)\n",
    "\n",
    "# visualize dataset\n",
    "demo.show_dataset()\n",
    "\n",
    "# run gradient descent to minimize cost\n",
    "g = multiclass_softmax; w = 0.1*np.random.randn(3,4); max_its = 5; \n",
    "weight_history = demo.newtons_method(g,w,max_its=max_its)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot our results, as in the previous Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot classification of space, individual learned classifiers (left panel) and joint boundary (middle panel), and cost-function panel in the right panel\n",
    "demo.show_complete_coloring(weight_history, cost = multiclass_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  End notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]  Care must be taken when implementing any cost function - or mathematical expression in general - involving the exponential function $e^{\\left(\\cdot\\right)}$ in Python. By nature the exponential function grows large very rapidly causing undesired 'overflow' issues even with moderate-sized exponents, e.g., $e^{1000}$. Large numbers like this cannot be stored explicitly on the computer and so are represented symbolically as $\\infty$. Additionally, the division of two such large numbers - which is a potentiality when evaluating the summands of the multi-class cost in equation (6) - is computed and stored as a NaN (not a number) causing severe numerical stability issues.\n",
    "\n",
    "One way we can guard against this issue is by normalizing the data - to fall within a relatively small range - and regularizing the the feature-touching weights, to punish/prevent large weight values. While a workable solution, in practice we can still run into overflow issues immediately after initialization especially when input is high-dimensional. It is therefore good practice to implement one's own version of the exponential function by capping the maximum value it can take, as shown below where $G$ is set to a relatively large value that does not send $e^G$ to $\\infty$.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "230px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "656.3px",
    "left": "0px",
    "right": "1228px",
    "top": "116.267px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
